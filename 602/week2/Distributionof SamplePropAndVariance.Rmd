---
title: "DATA 602 - The Distribution of Statistics (Continued)"
output: html_notebook
---
&copy; Jim Stallard 2022

<style>
div.pink pre { background-color:pink; }
div.pink pre.r { background-color:skyblue; }
</style>

# The Distribution of the Sample Proportion $\widehat{p}$

The sample proportion is another type of statistic. Represented by $\widehat{p}$ (p-hat), it represents the proportion of Bernoulli trials that are successful. Specifically, 

$$
\widehat{p} = \frac{X_{1} + X_{2} + \cdots + X_{n}}{n} = \frac{{\rm Binomial\:\:Random\:\:Variable}}{n}
$$

An Angus Reid survey/poll[^1] carried out in early August of 2022 found that of $n = 2279$ (presumed to be randomly chosen) Canadians, 56% indicated  
</br>
</br>
<center>
"it is a challenge/struggle to keep up with the cost of living"
</br>
</center>
</br>
due to the current inflationary pressures disposable income. 

Our current understanding of statistical inference would suggest that *approximately* 56% of all Canadians are struggling to keep up with the cost of living, due to the current level of inflation. 
</br>
</br>
If Angus Reid were to carry out another snapshot, perhaps in late-October, through a random sample of $n = 2279$ Canadians, we would expect - holding all things constant - that

$$
E(\text{Binomial}) = 2279(0.56) = 1276.25 \approx 1277 \:\: \text{Canadians}
$$
to indicate that they are "struggling to keep up with the cost of living". The standard deviation of the "how many" count $X$ can also be computed:

$$
SD(\text{Binomial}) = \sqrt{2279(0.56)(1 - 0.56)} = 23.69695 \approx 26.70 \:\: \text{Canadians}
$$
</br>
</br>
So what is the mean/expected value and the standard deviation of the sample proportion $\widehat{p}$? Recall from earlier material that

[^1]:(https://angusreid.org/inflation-bank-of-canada-grocery-prices/)

$$
\begin{aligned}
E(\widehat{p}) = & E\left(\frac{\text{Binomial}}{n}\right)\\
              = & \frac{E(\text{Binomial})}{n} \\
              = & \frac{np}{n}\\
E(\widehat{p})= & p
\end{aligned}
$$

From this, we see that the sample proportion is an **unbiased statistic/estimator** for the population proportion, as $E(\widehat{p}) = p$. The standard deviation of the sample proportion $\widehat{p}$ is

$$
\begin{align}
\sigma_{\widehat{p}} = & \sqrt{Var(\widehat{p})} \\
                     = & \sqrt{Var\left(\frac{\text{Binomial}}{n}\right)} \\
                     = & \sqrt{\frac{1}{n^2}*Var(\text{Binomial})} \\
                     = & \sqrt{\frac{1}{n^{2}}*np(1-p)} \\
\sigma_{\widehat{p}} = & \sqrt{\frac{p(1-p)}{n}}
\end{align}
$$

What about the distribution of $\widehat{p}$? Consider a random variable $X$ that counts "how many" Calgarians out of $n$ that have lost at least some income are currently unemployed.
</br>
</br>
Consider three different values of $n$: $n = 20$, $n = 100$, and $n = 500$. The respective distributions are provided below.

<div class = "pink">
```{r echo=TRUE}
nsample1 = 20
nsample2 = 100
nsample3 = 500
x = 0:nsample1
y = 0:nsample2
z = 0:nsample3
plot(x, dbinom(x,nsample1, 0.56), xlab="Number Out of 20 Struggling to Keep Up", ylab="Probability", main="Distribution of Count", type="h", col='blue')
plot(y, dbinom(y,nsample2, 0.56), xlab="Number Out of 100 Struggling to Keep Up", ylab="Probability", main="Distribution of Count", type="h", col='red')
plot(z, dbinom(z,nsample3, 0.56), xlab="Number Out of 500 Struggling to Keep Up", ylab="Probability", main="Distribution of Count", type="h", col='orange')
```
</div>
Now, suppose Angus Reid surveyed Canadians again with respect to this issue, and in doing so they found that from $n = 500$, $X = 295$ indicated they were "struggling to keep up with the cost of living". In this instance, 
$$
\widehat{p} = \frac{295}{500} = 0.59
$$
The distribution of the *sample proportion* based on $n = 500$ is then the Binomial distribution "divided" by 500:
<div class = "pink">
```{r echo=TRUE}
x = seq(200, 350, 0.1)
phat = (x/500)
plot(phat, dnorm(phat, 0.56, 0.022199099), yaxt = 'n', xlab="Values of the Sample Proportion", ylab = "Density", main="Distribution of Sample Proportion from n = 500", type="h", col='purple') + abline(v=0.59)
```
</div>

Let's consider the computation of another poll of $n = 500$ (perhaps in mid-October), and this next survey will result in *more than 60%* of Canadians struggling to keep up with the cost of living. 
</br>
</br>
The answer to this, we can use the `pnorm(x, mean, sd)` command, with a mean of $\mu_{\widehat{p}} = 0.56$ and a standard deviation of $\sigma_{\widehat{p}} = \sqrt{\frac{0.56(1-0.56)}{500}} = 0.022199 \approx 0.0222$. 
</br>
</br>
That is, compute the chance $P(\widehat{p} > 0.60)$ 
<div class = "pink">
```{r}
pnorm(0.60, mean=0.56, sd=0.02222) #computes P(phat <=0.60)
1 - pnorm(0.60, mean=0.56, sd=0.02222)
```
</div>
and $P(\widehat{p} > 0.60) = 0.03591611 \approx 0.03592$. 
</br>
</br>
What you are seeing here is the application of the Central Limit Theorem, applied to the sample proportion $\widehat{p}$. This can be done as long as the following condition

$$
np \geq 10 \:\: \text{and} \: \: n(1 - p) \geq 10 
$$
holds. In this case, it does:
$$
np = 500(0.56) = 280 \geq 10 \hspace{0.5in} n(1-p) = 500(0.44) = 220 \geq 10
$$
What we have done here is the following:
$$
\begin{align}
P(\widehat{p} > 0.60) = & P\left(\underbrace{\frac{\widehat{p} - \mu_{\widehat{p}}}{\sigma_{\widehat{p}}}}_{Z-transform}  > \frac{0.60 - \mu_{\widehat{p}}}{\sigma_{\widehat{p}}} \right) \\
                        = & P\left(Z > \frac{0.60 - \overbrace{0.56}^{\mu_{\widehat{p}}}}
                        {\underbrace{0.022222}_{\sigma_{\widehat{p}}}}   \right) \\
                        = & P(Z > 1.8018) \\
                        = & 0.0359
\end{align}
$$
or
<div class = "pink">
```{r}
1 - pnorm(1.8018)
```
</div>
</br>
</br>

**Example 1:** A recent poll Pollara[^2] of $n = 1325$ Canadians found that 44% wanted to end the constitutional monarchy - or wanted to end this connection to the British Crown</br>
</br>
</br>

Imagine you are hired to carry out a poll of $n$-Canadians in two months time, and you wish the results of your poll to be "off" from what you are presuming to be $p = 0.44$ by at most two percentage points (0.02) with probability of 0.95. 
</br>
</br>
How many Canadians would you need to randomly pick? $n = ?$
</br>
</br>
**Answer:** If the observed value of $\widehat{p}$ is to be "off" $p = 0.44$ by at most four-percentage points, or $e = 0.02$ (e for error), then
$$
\begin{align}
0.95 = &  P(-0.02 \leq \widehat{p} - 0.44 \leq 0.02) \\
0.95  = & P(|\widehat{p} - 0.44| \leq 0.02) \\
0.95   = & P\left(|\frac{\widehat{p} - 0.44}{\sigma_{\widehat{p}}} | \leq \frac{0.02}{\sigma_{\widehat{p}}}\right) \\
0.95     = & P\left(|Z| \leq \frac{\sqrt{n}*(0.02)}{\sqrt{0.44(1-0.44)}}\right)     \text{since}\:\:\left(\sigma_{\widehat{p}} = \sqrt{\frac{0.44(1 - 0.44)}{n}} \right) \\
\end{align}
$$

From a previous problem, the $z$-value that ensures a this is $z = 1.9599 = 1.96$:

[^2]:(https://www.pollara.com/wp-content/uploads/2022/09/Future_of_the-Crown_Pollara_public_release.pdf)

<div class = "pink">
```{r}
qnorm(0.975)
```
</div>

We now set this equal to the "right hand side" of the last probability expression:
$$
\begin{align}
\frac{\sqrt{n}*(0.02)}{\sqrt{0.44(1-0.44)}} = & 1.9599 \\
\sqrt{n} = & \frac{1.9599*\sqrt{0.44(1 - 0.44)}}{0.02} \\
n = &\left[  \frac{1.9599*\sqrt{0.44(1 - 0.44)}}{0.02}\right]^{2} \\
n = & 2366.18 \\
n \geq & 2367
\end{align}
$$
You would need to sample at least $n = 2367$ Canadians to be with 2% of $p = 0.44$ with 0.95 probability. 

<div class = "pink">
</div>
Using this function,

<div class = "pink">
```{r}
comp.samplesize.forp
```

```{r}
comp.samplesize.forp(0.44, 0.95, 0.02)
```
</div>

### A Question About Determining $n$ if the value of $p$ is unknown.

<div class = "pink">
```{r}
var.bernoulli = function(p)
{
  p*(1 - p)
}
```

```{r}
values.of.p = seq(0, 1, 0.01)
plot(values.of.p, var.bernoulli(values.of.p), xlab="Values of p", ylab = "Variance of Sample Proportion", type="l", col="red", main="Variance of the Bernoulli Random Variable for Various Values of p")
abline(v=0.5, col="blue")
```
</div>

The variance of the Bernoulli random variable, and in turn, the variance of $\widehat{p}$ is *maximized* when $p = 0.5$ for any value of $n$. 

So, when one has no idea about the value of the population proportion, then the "minimum sample size" formula becomes
$$
n \geq \frac{(1.96)^{2}*\overbrace{0.25}^{0.5*0.5}}{e^{2}} 
$$

**Illustration:** You are interested in estimating the value of $p$, the proportion of Canadians who will do something to commemorate to observe Canada's National Day for Truth and Reconciliation, or "Orange Shirt Day" (September 30th). In doing so, you wish to have 95% "trust" that the sample proportion $\widehat{p}$ computed from your sample is within three percentage points of the *true, but unknown value* of $p$. 


How large must your random sample be? That is, $n = $?
</br>
</br>
**Answer:** In this instance, set the value of $p = 0.50$ - as was done above - to compute the minimum sample size $n$. The "truth level" is 0.95, which means $Z_{0.975} = 1.9599 \approx 1.96$, and the margin of error $e = 0.03$. 

<div class = "pink">
```{r}
comp.samplesize.forp(0.50, 0.95, 0.03) #set p = 0.5
```
</div>

Therefore, you must randomly sample $n = 1068$ Canadians in order to esimtate the proportion of *all* Canadians who will do something to commemorate the National Day for Truth and Reconciliation. 
</br>
</br>

[^2]:(https://www.pollara.com/wp-content/uploads/2022/09/Future_of_the-Crown_Pollara_public_release.pdf)


-----------------------------------

## Time to Play 1

In the game Roulette, a wheel with 38 numbers $0, 1, 2, \cdots, 36, 00$ - each having its own equal sized pocket - is spun. A small white marble is placed in a track above the wheel and spun in the opposite direction of the wheel. The white ball eventually falls into one of the 38 pockets. 

There are numerous "bets" that can occur in a game of Roulette. One is to bet on <font color = "red">RED</font>. The numbers "0" and "00" are <font color="green">GREEN</font>, the 18 of the numbers are <font color="red">RED</font>, and 18 are black[^3]. 

(a) You are to play Roulette 100 times, each time betting on <font color="red">RED</font>. Using R, generate the distribution of $\widehat{p}$, the proportion of times that your bet on <font color="red">RED</font> will be successful. 
</br>
</br>
**Answer:** 
<div style="margin-bottom:250px;">
</div>

(b) Aaron likes to play roulette. He claims that when he bets on <font color="RED">RED</font> he wins more than 60% of the time. What do you think of Aaron's claim? Assume he plays $n = 100$ games.  
</br>
</br>
**Answer:** 
<div style="margin-bottom:300px;">
</div>


[^3]:(https://betandslots.com/guides/roulette-numbers/)

-----------------------------------

# Distribution of the Sample Variance $S^{2}$

## Using Simulation to Investigate the Distribution of the Sample Variance Through the Sample Standard Deviation

The sample variance is also a random variable. Why? It is a *function* of the sample mean $\overline{X}$, we we have just learned is a random variable that is approximately modeled by the Normal distribution for $n \geq 25$. 
$$
S^{2} = \frac{\sum_{i=1}^{n}(x_{i} - \overline{X})^{2}}{n - 1}
$$
What does the distribution of the sample *standard deviation* $S$ look like? 

Similiar to the simulation conducted in *Illustration 1*, below is the code that enables you to select a simple random sample (this is the default form of sampling that the `sample` function uses) from the population of flights data.frame *flights** using a sample size of (i) $n = 5$ (ii) $n = 15$, each time computing the sample standard deviation of hte sample of either 5 or 15 **distance**s that have been chosen.
<div class = "pink">
```{r}
nsamples = 1000  #no. of simulations
sample.sdn5 = numeric(nsamples) #data vector to hold 1000 sample standard deviations
for(i in 1:nsamples){
  sdata = sample(na.omit(flights$distance), 5, replace=FALSE) #randomly pick 5 flights w/o replacement
  sample.sdn5[i] = sd(sdata) #compute the standard deviation of the five flights
}
samplestats.df3 = data.frame(sample.sdn5)
```

```{r}
samplestats.df3 #A view of the data frame....
```


```{r}
ggplot(samplestats.df3, aes(x = sample.sdn5)) + geom_histogram(col='orange', fill='yellow', binwidth=50) + xlab("Values of Sample Standard Deviation") + ylab("Count") + ggtitle("Distribution of 1000 Sample Standard Deviations (n=5)")
#
cat("The average of these 1000 values of the sample standard deviation based on n = 5 is", mean(~sample.sdn5, data=samplestats.df3), "miles and the standard deviation is",sd(~xbar, data=samplestats.df3),"miles. \n")
```
</div>

Now, what would happen if we *squared* each computed value of $S$: $S_{1}, S_{2}, \cdots, S_{1000}$ in this simulation and viewed the distibution of the resulting sample variance $S^{2}$?
<div class = "pink">
```{r}
samplestats.df3 = samplestats.df3 %>% 
  mutate(sample.varn5 = (sample.sdn5)^{2})
head(samplestats.df3, 4)
```
A histogram and density plot of the distribution of the sample variance $S^{2}$ is provided below.
<div class = "pink">
```{r}
ggplot(samplestats.df3, aes(x = sample.varn5)) + geom_histogram(col='orange', fill='yellow', binwidth=20000) + xlab("Values of the Sample Variance") + ylab("Count") + ggtitle("Distribution of Sample Variance (n = 5)")
#
ggplot(samplestats.df3, aes(x = sample.varn5)) + geom_density(col='orange', fill='yellow') + xlab("Values of the Sample Variance") + ylab("Density") + ggtitle("Distribution of Sample Variance (n = 5)")
```
</div>

**Extension of Distribution of $S$:** We will Re-run the code that generated the distibution of $S$ from a sample of $n = 5$ changing the line
<div class = "pink">
```{r}
sample.sdn5[i] = sd(sdata) #computes the standard deviation of each  of 1000 samples of n = 5
```
to
```{r}
sample.varn15 = var(sdata) #computes the variance of each  of 1000 samples of n = 15
```

```{r}
nsamples = 1000  #no. of simulations
sample.varn15 = numeric(nsamples) #data vector to hold 1000 sample variances
for(i in 1:nsamples){
  sdata = sample(na.omit(flights$distance), 15, replace=FALSE) #randomly pick 15 flights w/o replacement
  sample.varn15[i] = var(sdata) #compute the variance of the 15 flights
}
samplestats.df4 = data.frame(sample.varn15)
head(samplestats.df4, 3)
```
</div>

The histogram and density-plot of $S^{2}$ based on $n = 15$ is provided below.
<div class = "pink">
```{r}
ggplot(samplestats.df4, aes(x = sample.varn15)) + geom_histogram(col='orange', fill='yellow', binwidth=20000) + xlab("Values of the Sample Variance") + ylab("Count") + ggtitle("Histogram of Sample Variance (n = 15)")
#
ggplot(samplestats.df4, aes(x = sample.varn15)) + geom_density(col='orange', fill='yellow') + xlab("Values of the Sample Variance") + ylab("Density") + ggtitle("Density Plot of Sample Variance (n = 15)")
```
</div>

You can see that as the sample size increases from $n = 5$ to $n = 15$, the distribuiton of $S^{2}$ becomes less right-skewed. 
</br>
</br>

## A Transformation of the Sample Variance $S^{2}$

Now suppose we create a new variable which results from *transforming each of these values of* $S^{2}$ by the fraction $\frac{n - 1}{\sigma^{2}}$, where $\sigma = 733.233$ miles.

<div class = "pink">
```{r}
samplestats.df4 = samplestats.df4 %>%
  mutate(transformed.var = ((15 - 1)/(733.233^{2})*sample.varn15)) 
head(samplestats.df4, 4)
```
The distribution of this new variable **transformed.var** is
```{r}
ggplot(samplestats.df4, aes(x = transformed.var)) + geom_histogram(col='orange', fill='yellow', binwidth=2) + xlab("Values of the Transformed Sample Variance") + ylab("Count") + ggtitle("Distribution of Transformed Sample Variance (n = 15)")
#
ggplot(samplestats.df4, aes(x = transformed.var)) + geom_density(col='orange', fill='yellow') + xlab("Values of the Sample Variance") + ylab("Density") + ggtitle("Distribution of Transformed Sample Variance (n = 15)")
```
the mean and standard deviation of this transformed variance variable **transformed.var** is 
```{r}
mean(~transformed.var, data=samplestats.df4)
sd(~transformed.var, data=samplestats.df4)
```
</div>

This finding provides us with some insights into the distribution of the *transformed* value of the sample variance $S^{2}$:
</br>
</br>
**Result:** When the sample variance $S^{2}$ is transformed by
$$
\frac{(n - 1)*S^{2}}{\sigma^{2}}
$$

where $n$ is the sample size and $\sigma$ is the *population variance*, the resulting transformation is a random variable that can be approximated by the Chi-square ($\chi^{2}$) distribution with a mean of $n - 1$ and a standard deviation of $\sqrt{2(n-1)}$. The $n - 1$ term is called the **degrees of freedom** of the $\chi^{2}$ distribution, or $\chi^{2}_{df=n-1}$. 
</br>
</br>
Probabilties associated with the $\chi^{2}$ can be computed in R with either the `dchisq(x, df)` or the `pchisq(p, df)` commands. 
</br>
</br>

**Example 1:** Let's return to the **sampleflights** data frame which we loaded and worked with last week. Specifically, the variable *distance*. The observed value of the sample standard deviation. Recall the value of the population standard deviation is $\sigma = 733.233$. 
</br>
</br>
The sample standard deviation is from the sample of $n$ flights was computed as
<div class = "pink">
```{r}
favstats(~distance, data=sampleflights)
```
</div>
The observed value of the sample standard deviation is computed to be 
$$
S = 743.8267\:\;\text{miles}
$$
With respect to the variable *distance* there are no missing values, so $n = 1000$. 
</br>
</br>
(a) Compute the probability that another random sample of $n = 1000$ flights will produce a sample standard deviation that is between 700 miles and 725 miles.
</br>
</br>
**Answer:** We wish to compute $P(700 \leq S \leq 725)$. 
$$
\begin{aligned}
P(700 \leq S \leq 725) = & P(700^{2} \leq S^{2} \leq 725^{2})  \\
                       = & P \left(\frac{(n - 1)*700^{2}}{\sigma^{2}} \leq \frac{(n - 1)*S^{2}}{\sigma^{2}} \leq \frac{(n - 1)*725^{2}}{\sigma^{2}} \right)  \\
= & P \left(\frac{(1000 - 1)*700^{2}}{733.233^{2}} \leq \chi^{2}_{1000 - 1} \leq \frac{(1000 - 1)*725^{2}}{733.233^{2}} \right)  \\
= & P(910.4949 \leq \chi^{2}_{999} \leq 976.6917) \\
= & \underbrace{P(\chi^{2}_{999} \leq 976.6917)}_{\text{pchisq(976.6917, 999)}} - \underbrace{P(\chi^{2}_{999} \leq 910.4949)}_{\text{pchisq(910.4949, 999)}} \\
= & 0.2914636 \\
\approx & 0.2915 
\end{aligned}
$$

<div class = "pink">
```{R}
pchisq(976.6917, 999) - pchisq(910.4949, 999)  #computes the differnce between two cumulative probabilies
```
</div>
and $P(700 \leq S \leq 725) = 0.2915$. 
</br>
</br>

**Example 2:** From Example 1, compute the probability that another sample of $n = 1000$ departing flights from the 3-NYc airiports will yield a sample standard devaition that exceeds the observed value of S of 743.83 (rounded to two decimals)
</br>
</br>
**Answer:** Here we are required to compute $P(S > 743.83)$,
$$
\begin{aligned}
P(S > 743.83) = & P( S^{2}  > 743.83^{2}  ) \\
= & \left(\frac{(n - 1)*S^{2}}{\sigma^{2}} > \frac{(n - 1)*743.83^{2}}{\sigma^{2}}  \right) \\
= & \left(\chi^{2}_{999} > \frac{(1000 - 1)*743.83^{2}}{733.233^{2}}  \right) \\
= & P(\chi^{2}_{999} > 1028.0846) \\
= & 1 - \underbrace{P(\chi^{2}_{999} \leq 1028.0846)}_{\text{pchisq(1028.0846, 999)}} \\
= & 0.1027749 \\
\approx & 0.1028
\end{aligned}
$$
<div class = "pink">
```{r}
1 - pchisq(1028.0846, 1000 - 1) #second argument is the degrees of freedom (n - 1)
```
</div>
</br>
</br>

## Time to Play 2

Refer to the **uselectiondata** file that was used last Thursday and re-employed at the start of today's class. 

</br>

Take a random sample of $n = 50$ counties from the $N = 3143$ counties, and the variable **Median.Earnings.2010** and compute/refer to the sample standard deviation.
In doing so, use the code

```{r}
timetoplay2.df <- sample(uselectiondata, n = 50, replace=FALSE)
```

(a) Compute the value of the sample variance, $S^{2}$ of your sample of $n = 50$ counties. 
</br>
</br>
**Answer:** 
<div style="margin-bottom:200px;">
</div>

(b) The population standard deviation was computed to be $\sigma_{Median.Earnings.2010} = \$5078$. 
</br>
</br>
Compute the chance that if you took another random sample of $n = 50$ counties, you would observe a sample standard deviation at least as much as the one you observed in the sample you took last Thursday. 
</br>
</br>
**Answer:** 
<div style="margin-bottom:200px;">
</div>

(c) Generate a distribution of the sample standard deviation, use 1000 iterations and a sample size of $n = 50$. Visualize this distribution, locating the value of $S$ computed in part (a). 
</br>
</br>
What proportion of the standard deviations in your simulation *exceed* the value you computed in part (a)? How does this compare to the $P(S > S_{your\:value})$? 
</br>
</br>
**Answer:** 
<div style="margin-bottom:200px;">
</div>










